{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33652b14-0a71-4a6d-b2a2-613c5c0ee620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T14:58:20.228487Z",
     "iopub.status.busy": "2024-10-14T14:58:20.224538Z",
     "iopub.status.idle": "2024-10-14T14:58:27.371756Z",
     "shell.execute_reply": "2024-10-14T14:58:27.371458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spark-stubs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SparkSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO SparkContext: Running Spark version 3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO SparkContext: OS info Linux, 6.6.13-200.fc39.x86_64, amd64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO SparkContext: Java version 17.0.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO ResourceUtils: ==============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO ResourceUtils: No custom resources configured for spark.driver.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO ResourceUtils: ==============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO SparkContext: Submitted application: ab46071d-cb14-4597-be91-29101c75ab66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 15360, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO ResourceProfileManager: Added ResourceProfile id: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO SecurityManager: Changing view acls to: jovyan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO SecurityManager: Changing modify acls to: jovyan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO SecurityManager: Changing view acls groups to: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO SecurityManager: Changing modify acls groups to: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: jovyan; groups with view permissions: EMPTY; users with modify permissions: jovyan; groups with modify permissions: EMPTY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO Utils: Successfully started service 'sparkDriver' on port 2222.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO SparkEnv: Registering MapOutputTracker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:22 INFO S3ShuffleManager: Configured S3ShuffleManager (spark-s3-shuffle-0.9.5 for 3.4.0_2.12.17).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkEnv: Registering BlockManagerMaster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-26412cc6-f031-4cf9-a1af-ddd76d46ae47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/scala-kernel-api_2.12.18/0.14.0-RC14/scala-kernel-api_2.12.18-0.14.0-RC14.jar at spark://spark-notebook:2222/jars/scala-kernel-api_2.12.18-0.14.0-RC14.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler_2.12.18/3.0.0-M0-56-1bcbe7f6/ammonite-compiler_2.12.18-3.0.0-M0-56-1bcbe7f6.jar at spark://spark-notebook:2222/jars/ammonite-compiler_2.12.18-3.0.0-M0-56-1bcbe7f6.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-repl-api_2.12.18/3.0.0-M0-56-1bcbe7f6/ammonite-repl-api_2.12.18-3.0.0-M0-56-1bcbe7f6.jar at spark://spark-notebook:2222/jars/ammonite-repl-api_2.12.18-3.0.0-M0-56-1bcbe7f6.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/jitpack.io/com/github/jupyter/jvm-repr/0.4.0/jvm-repr-0.4.0.jar at spark://spark-notebook:2222/jars/jvm-repr-0.4.0.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/io/get-coursier/interface/1.0.19/interface-1.0.19.jar at spark://spark-notebook:2222/jars/interface-1.0.19.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-collection-compat_2.12/2.11.0/scala-collection-compat_2.12-2.11.0.jar at spark://spark-notebook:2222/jars/scala-collection-compat_2.12-2.11.0.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/interpreter-api_2.12/0.14.0-RC14/interpreter-api_2.12-0.14.0-RC14.jar at spark://spark-notebook:2222/jars/interpreter-api_2.12-0.14.0-RC14.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/jupyter-api_2.12/0.14.0-RC14/jupyter-api_2.12-0.14.0-RC14.jar at spark://spark-notebook:2222/jars/jupyter-api_2.12-0.14.0-RC14.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/scalaparse_2.12/3.0.0/scalaparse_2.12-3.0.0.jar at spark://spark-notebook:2222/jars/scalaparse_2.12-3.0.0.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.12/2.2.0/scala-xml_2.12-2.2.0.jar at spark://spark-notebook:2222/jars/scala-xml_2.12-2.2.0.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar at spark://spark-notebook:2222/jars/javassist-3.21.0-GA.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/github/javaparser/javaparser-core/3.2.5/javaparser-core-3.2.5.jar at spark://spark-notebook:2222/jars/javaparser-core-3.2.5.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler-interface_2.12.18/3.0.0-M0-56-1bcbe7f6/ammonite-compiler-interface_2.12.18-3.0.0-M0-56-1bcbe7f6.jar at spark://spark-notebook:2222/jars/ammonite-compiler-interface_2.12.18-3.0.0-M0-56-1bcbe7f6.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-util_2.12/3.0.0-M0-56-1bcbe7f6/ammonite-util_2.12-3.0.0-M0-56-1bcbe7f6.jar at spark://spark-notebook:2222/jars/ammonite-util_2.12-3.0.0-M0-56-1bcbe7f6.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/mainargs_2.12/0.3.0/mainargs_2.12-0.3.0.jar at spark://spark-notebook:2222/jars/mainargs_2.12-0.3.0.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/geny_2.12/1.0.0/geny_2.12-1.0.0.jar at spark://spark-notebook:2222/jars/geny_2.12-1.0.0.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-interp-api_2.12.18/3.0.0-M0-56-1bcbe7f6/ammonite-interp-api_2.12.18-3.0.0-M0-56-1bcbe7f6.jar at spark://spark-notebook:2222/jars/ammonite-interp-api_2.12.18-3.0.0-M0-56-1bcbe7f6.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fastparse_2.12/3.0.0/fastparse_2.12-3.0.0.jar at spark://spark-notebook:2222/jars/fastparse_2.12-3.0.0.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/os-lib_2.12/0.9.1/os-lib_2.12-0.9.1.jar at spark://spark-notebook:2222/jars/os-lib_2.12-0.9.1.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fansi_2.12/0.4.0/fansi_2.12-0.4.0.jar at spark://spark-notebook:2222/jars/fansi_2.12-0.4.0.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/pprint_2.12/0.8.1/pprint_2.12-0.8.1.jar at spark://spark-notebook:2222/jars/pprint_2.12-0.8.1.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/sourcecode_2.12/0.3.0/sourcecode_2.12-0.3.0.jar at spark://spark-notebook:2222/jars/sourcecode_2.12-0.3.0.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/scala-kernel-api_2.12.18/0.14.0-RC14/scala-kernel-api_2.12.18-0.14.0-RC14-sources.jar at spark://spark-notebook:2222/jars/scala-kernel-api_2.12.18-0.14.0-RC14-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler_2.12.18/3.0.0-M0-56-1bcbe7f6/ammonite-compiler_2.12.18-3.0.0-M0-56-1bcbe7f6-sources.jar at spark://spark-notebook:2222/jars/ammonite-compiler_2.12.18-3.0.0-M0-56-1bcbe7f6-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-repl-api_2.12.18/3.0.0-M0-56-1bcbe7f6/ammonite-repl-api_2.12.18-3.0.0-M0-56-1bcbe7f6-sources.jar at spark://spark-notebook:2222/jars/ammonite-repl-api_2.12.18-3.0.0-M0-56-1bcbe7f6-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/jitpack.io/com/github/jupyter/jvm-repr/0.4.0/jvm-repr-0.4.0-sources.jar at spark://spark-notebook:2222/jars/jvm-repr-0.4.0-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/io/get-coursier/interface/1.0.19/interface-1.0.19-sources.jar at spark://spark-notebook:2222/jars/interface-1.0.19-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-collection-compat_2.12/2.11.0/scala-collection-compat_2.12-2.11.0-sources.jar at spark://spark-notebook:2222/jars/scala-collection-compat_2.12-2.11.0-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/interpreter-api_2.12/0.14.0-RC14/interpreter-api_2.12-0.14.0-RC14-sources.jar at spark://spark-notebook:2222/jars/interpreter-api_2.12-0.14.0-RC14-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/jupyter-api_2.12/0.14.0-RC14/jupyter-api_2.12-0.14.0-RC14-sources.jar at spark://spark-notebook:2222/jars/jupyter-api_2.12-0.14.0-RC14-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/scalaparse_2.12/3.0.0/scalaparse_2.12-3.0.0-sources.jar at spark://spark-notebook:2222/jars/scalaparse_2.12-3.0.0-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.12/2.2.0/scala-xml_2.12-2.2.0-sources.jar at spark://spark-notebook:2222/jars/scala-xml_2.12-2.2.0-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA-sources.jar at spark://spark-notebook:2222/jars/javassist-3.21.0-GA-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/github/javaparser/javaparser-core/3.2.5/javaparser-core-3.2.5-sources.jar at spark://spark-notebook:2222/jars/javaparser-core-3.2.5-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler-interface_2.12.18/3.0.0-M0-56-1bcbe7f6/ammonite-compiler-interface_2.12.18-3.0.0-M0-56-1bcbe7f6-sources.jar at spark://spark-notebook:2222/jars/ammonite-compiler-interface_2.12.18-3.0.0-M0-56-1bcbe7f6-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-util_2.12/3.0.0-M0-56-1bcbe7f6/ammonite-util_2.12-3.0.0-M0-56-1bcbe7f6-sources.jar at spark://spark-notebook:2222/jars/ammonite-util_2.12-3.0.0-M0-56-1bcbe7f6-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/mainargs_2.12/0.3.0/mainargs_2.12-0.3.0-sources.jar at spark://spark-notebook:2222/jars/mainargs_2.12-0.3.0-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/geny_2.12/1.0.0/geny_2.12-1.0.0-sources.jar at spark://spark-notebook:2222/jars/geny_2.12-1.0.0-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-interp-api_2.12.18/3.0.0-M0-56-1bcbe7f6/ammonite-interp-api_2.12.18-3.0.0-M0-56-1bcbe7f6-sources.jar at spark://spark-notebook:2222/jars/ammonite-interp-api_2.12.18-3.0.0-M0-56-1bcbe7f6-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fastparse_2.12/3.0.0/fastparse_2.12-3.0.0-sources.jar at spark://spark-notebook:2222/jars/fastparse_2.12-3.0.0-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/os-lib_2.12/0.9.1/os-lib_2.12-0.9.1-sources.jar at spark://spark-notebook:2222/jars/os-lib_2.12-0.9.1-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fansi_2.12/0.4.0/fansi_2.12-0.4.0-sources.jar at spark://spark-notebook:2222/jars/fansi_2.12-0.4.0-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/pprint_2.12/0.8.1/pprint_2.12-0.8.1-sources.jar at spark://spark-notebook:2222/jars/pprint_2.12-0.8.1-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/sourcecode_2.12/0.3.0/sourcecode_2.12-0.3.0-sources.jar at spark://spark-notebook:2222/jars/sourcecode_2.12-0.3.0-sources.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/almond-spark_2.12/0.13.2/almond-spark_2.12-0.13.2.jar at spark://spark-notebook:2222/jars/almond-spark_2.12-0.13.2.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/ammonite-spark_2.12/0.13.5/ammonite-spark_2.12-0.13.5.jar at spark://spark-notebook:2222/jars/ammonite-spark_2.12-0.13.5.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/github/plokhotnyuk/jsoniter-scala/jsoniter-scala-core_2.12/2.13.5/jsoniter-scala-core_2.12-2.13.5.jar at spark://spark-notebook:2222/jars/jsoniter-scala-core_2.12-2.13.5.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.49.v20220914/jetty-server-9.4.49.v20220914.jar at spark://spark-notebook:2222/jars/jetty-server-9.4.49.v20220914.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar at spark://spark-notebook:2222/jars/javax.servlet-api-3.1.0.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.49.v20220914/jetty-http-9.4.49.v20220914.jar at spark://spark-notebook:2222/jars/jetty-http-9.4.49.v20220914.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.49.v20220914/jetty-io-9.4.49.v20220914.jar at spark://spark-notebook:2222/jars/jetty-io-9.4.49.v20220914.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.49.v20220914/jetty-util-9.4.49.v20220914.jar at spark://spark-notebook:2222/jars/jetty-util-9.4.49.v20220914.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repos.spark-packages.org/graphframes/graphframes/0.8.2-spark3.2-s_2.12/graphframes-0.8.2-spark3.2-s_2.12.jar at spark://spark-notebook:2222/jars/graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.16/slf4j-api-1.7.16.jar at spark://spark-notebook:2222/jars/slf4j-api-1.7.16.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/spark-stubs_32_2.12/0.13.5/spark-stubs_32_2.12-0.13.5.jar at spark://spark-notebook:2222/jars/spark-stubs_32_2.12-0.13.5.jar with timestamp 1728917902037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO TransportClientFactory: Successfully created connection to spark-master/172.30.207.45:7077 after 30 ms (0 ms spent in bootstraps)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20241014145823-0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7777.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO NettyBlockTransferService: Server created on spark-notebook 0.0.0.0:7777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, spark-notebook, 7777, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO BlockManagerMasterEndpoint: Registering block manager spark-notebook:7777 with 2.2 GiB RAM, BlockManagerId(driver, spark-notebook, 7777, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, spark-notebook, 7777, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, spark-notebook, 7777, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:24 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:24 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:24 INFO MetricsSystemImpl: s3a-file-system metrics system started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:24 INFO DirectoryPolicyImpl: Directory markers will be kept\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:25 INFO SingleEventLogFileWriter: Logging events to s3a://hpc-hd-spark/spark-logs/app-20241014145823-0077.zstd.inprogress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:25 WARN S3ABlockOutputStream: Application invoked the Syncable API against stream writing to spark-logs/app-20241014145823-0077.zstd.inprogress. This is unsupported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:25 INFO Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:25 INFO ExecutorAllocationManager: Dynamic allocation is enabled without a shuffle service.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:25 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"http://spark-notebook:4040\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 14:58:25 WARN SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/home/jovyan/work/spark-checkpoint' appears to be on the local filesystem.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$exec.$\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $exec.spark_functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb19fd68",
   "metadata": {},
   "source": [
    "# 2. Defragment overlapping pieces to one id\n",
    "\n",
    "Create an initial defragmentation of the piece_ids by mapping all pieces that overlap sufficiently in a given text document to one id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2428db5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T14:58:27.390910Z",
     "iopub.status.busy": "2024-10-14T14:58:27.390606Z",
     "iopub.status.idle": "2024-10-14T14:58:30.905833Z",
     "shell.execute_reply": "2024-10-14T14:58:30.903152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types.{StructType, StructField, IntegerType, ArrayType}\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.catalyst.encoders.RowEncoder\u001b[39m\n",
       "\u001b[36minput_type\u001b[39m: \u001b[32mStructType\u001b[39m = \u001b[33mStructType\u001b[39m(\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"trs_start\"\u001b[39m, IntegerType, \u001b[32mtrue\u001b[39m, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"trs_end\"\u001b[39m, IntegerType, \u001b[32mtrue\u001b[39m, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"piece_id\"\u001b[39m, IntegerType, \u001b[32mtrue\u001b[39m, {})\n",
       ")\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable.ArrayBuffer\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Aggregator\u001b[39m\n",
       "defined \u001b[32mobject\u001b[39m \u001b[36mGetPieceIdMapping\u001b[39m\n",
       "\u001b[36mres2_7\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mUserDefinedFunction\u001b[39m = \u001b[33mUserDefinedAggregator\u001b[39m(\n",
       "  ammonite.$sess.cell2$Helper$GetPieceIdMapping$@6efb6d35,\n",
       "  \u001b[33mExpressionEncoder\u001b[39m(\n",
       "    \u001b[33mIf\u001b[39m(\n",
       "      \u001b[33mIsNull\u001b[39m(\n",
       "        \u001b[33mBoundReference\u001b[39m(\u001b[32m0\u001b[39m, \u001b[33mObjectType\u001b[39m(interface org.apache.spark.sql.Row), \u001b[32mtrue\u001b[39m)\n",
       "      ),\n",
       "      \u001b[33mLiteral\u001b[39m(\n",
       "        \u001b[32mnull\u001b[39m,\n",
       "        \u001b[33mStructType\u001b[39m(\n",
       "          \u001b[33mStructField\u001b[39m(\u001b[32m\"trs_start\"\u001b[39m, IntegerType, \u001b[32mtrue\u001b[39m, {}),\n",
       "          \u001b[33mStructField\u001b[39m(\u001b[32m\"trs_end\"\u001b[39m, IntegerType, \u001b[32mtrue\u001b[39m, {}),\n",
       "          \u001b[33mStructField\u001b[39m(\u001b[32m\"piece_id\"\u001b[39m, IntegerType, \u001b[32mtrue\u001b[39m, {})\n",
       "        )\n",
       "      ),\n",
       "      \u001b[33mCreateNamedStruct\u001b[39m(\n",
       "        \u001b[33mArraySeq\u001b[39m(\n",
       "          \u001b[33mLiteral\u001b[39m(trs_start, StringType),\n",
       "          \u001b[33mIf\u001b[39m(\n",
       "            \u001b[33mInvoke\u001b[39m(\n",
       "              \u001b[33mBoundReference\u001b[39m(\n",
       "                \u001b[32m0\u001b[39m,\n",
       "                \u001b[33mObjectType\u001b[39m(interface org.apache.spark.sql.Row),\n",
       "                \u001b[32mtrue\u001b[39m\n",
       "              ),\n",
       "              \u001b[32m\"isNullAt\"\u001b[39m,\n",
       "              BooleanType,\n",
       "              \u001b[33mList\u001b[39m(\u001b[33mLiteral\u001b[39m(\u001b[32m0\u001b[39m, IntegerType)),\n",
       "              \u001b[33mList\u001b[39m(),\n",
       "              \u001b[32mtrue\u001b[39m,\n",
       "              \u001b[32mtrue\u001b[39m,\n",
       "              \u001b[32mtrue\u001b[39m\n",
       "            ),\n",
       "            \u001b[33mLiteral\u001b[39m(\u001b[32mnull\u001b[39m, IntegerType),\n",
       "            \u001b[33mInvoke\u001b[39m(\n",
       "              \u001b[33mValidateExternalType\u001b[39m(\n",
       "                \u001b[33mGetExternalRowField\u001b[39m(\n",
       "                  \u001b[33mBoundReference\u001b[39m(\n",
       "                    \u001b[32m0\u001b[39m,\n",
       "..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, ArrayType}\n",
    "import org.apache.spark.sql.catalyst.encoders.RowEncoder\n",
    "\n",
    "val input_type = StructType(Seq(\n",
    "    StructField(\"trs_start\",IntegerType),\n",
    "    StructField(\"trs_end\",IntegerType),\n",
    "    StructField(\"piece_id\",IntegerType)\n",
    "))\n",
    "\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "import org.apache.spark.sql.expressions.Aggregator\n",
    "\n",
    "object GetPieceIdMapping extends Aggregator[Row, ArrayBuffer[(Int,Int,Int)], Int] {\n",
    "  import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n",
    "\n",
    "  // A zero value for this aggregation. Should satisfy the property that any b + zero = b\n",
    "  def zero: ArrayBuffer[(Int,Int,Int)] = ArrayBuffer()\n",
    "  // Combine two values to produce a new value. For performance, the function may modify `buffer`\n",
    "  // and return it instead of constructing a new object\n",
    "  def reduce(to_check: ArrayBuffer[(Int,Int,Int)], row: Row): ArrayBuffer[(Int,Int,Int)] = {\n",
    "      val t_start = row.getInt(0)\n",
    "      // check existing buffer for the last piece that is 180 characters \n",
    "      // before the current start offset\n",
    "      val idx = to_check.indexWhere(_._1 >= t_start - 180)\n",
    "      // if 0 then clear the buffer\n",
    "      // otherwise remove unsuitable pieces\n",
    "      if (idx < 0) to_check.clear() else to_check.remove(0, idx)\n",
    "      // add the current piece to the end of buffer\n",
    "      to_check += ((t_start,row.getInt(1),row.getInt(2)))\n",
    "      to_check\n",
    "  }\n",
    "  // Merge two intermediate values\n",
    "  def merge(b1: ArrayBuffer[(Int,Int,Int)], b2: ArrayBuffer[(Int,Int,Int)]): ArrayBuffer[(Int,Int,Int)] = {\n",
    "//      b1 ++= b2 & sort\n",
    "      throw new UnsupportedOperationException()\n",
    "  }\n",
    "  // Transform the output of the reduction\n",
    "  def finish(to_check: ArrayBuffer[(Int,Int,Int)]): Int = {\n",
    "      val (t_start, t_end, piece_id) = to_check.last\n",
    "      to_check.find(r => {\n",
    "          val limit = math.min(\n",
    "              math.max(\n",
    "                  math.min(t_end - t_start, r._2 - r._1)\n",
    "                  /4, 10),\n",
    "              180)\n",
    "          math.abs(r._1 - t_start) <= limit && math.abs(r._2 - t_end) <= limit\n",
    "      }).get._3 // get the id of the first piece that is valid\n",
    "  }\n",
    "  // Specifies the Encoder for the intermediate value type\n",
    "  def bufferEncoder: Encoder[ArrayBuffer[(Int,Int,Int)]] = ExpressionEncoder()\n",
    "  // Specifies the Encoder for the final output value type\n",
    "  def outputEncoder: Encoder[Int] = Encoders.scalaInt\n",
    "}\n",
    "\n",
    "// Register the function to access it\n",
    "spark.udf.register(\"get_piece_id_mapping\", functions.udaf(GetPieceIdMapping,Encoders.row(input_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282ecefa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T14:58:30.912127Z",
     "iopub.status.busy": "2024-10-14T14:58:30.909782Z",
     "iopub.status.idle": "2024-10-14T14:58:39.062780Z",
     "shell.execute_reply": "2024-10-14T14:58:39.061284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var comm = Jupyter.notebook.kernel.comm_manager.new_comm('cancel-stage-7c6095cd-2d13-425d-9b31-2c0cc28f6a97', {});\n",
       "\n",
       "function cancelStage(stageId) {\n",
       "  console.log('Cancelling stage ' + stageId);\n",
       "  comm.send({ 'stageId': stageId });\n",
       "}\n",
       "</script>\n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:92</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(0);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 1\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36morig_pieces\u001b[39m: \u001b[32mDataFrame\u001b[39m = [piece_id: bigint, trs_id: bigint ... 2 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val orig_pieces = get_a3s(\"orig_pieces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cee6b92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T14:58:39.090600Z",
     "iopub.status.busy": "2024-10-14T14:58:39.066320Z",
     "iopub.status.idle": "2024-10-14T15:00:08.709791Z",
     "shell.execute_reply": "2024-10-14T15:00:08.708325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:96</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(1);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 51\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:96</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(3);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 43\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:92</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(4);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 1\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mpiece_id_mappings\u001b[39m: \u001b[32mDataFrame\u001b[39m = [orig_piece_id: bigint, defrag_mapping: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val piece_id_mappings = materialise_a3s_if_not_exists(\n",
    "    \"piece_id_mappings_tmp\", \n",
    "    spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        piece_id AS orig_piece_id,\n",
    "        get_piece_id_mapping(trs_start,trs_end,piece_id) \n",
    "            OVER (PARTITION BY trs_id ORDER BY trs_start, piece_id) \n",
    "            AS defrag_mapping\n",
    "    FROM orig_pieces\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd770f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T15:00:08.714308Z",
     "iopub.status.busy": "2024-10-14T15:00:08.712834Z",
     "iopub.status.idle": "2024-10-14T15:02:12.127923Z",
     "shell.execute_reply": "2024-10-14T15:02:12.126598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">rdd at spark_functionality.sc:134</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(5);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 48\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">rdd at spark_functionality.sc:134</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(7);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 5\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">rdd at spark_functionality.sc:134</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(9);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 5\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">zipWithIndex at spark_functionality.sc:134</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(12);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 4\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:96</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(15);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 5\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:92</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(16);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 1\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "materialise_row_numbers(\n",
    "  \"defrag_id_mapping\",\n",
    "  spark.sql(\"\"\"\n",
    "    SELECT DISTINCT defrag_mapping\n",
    "    FROM piece_id_mappings_tmp\n",
    "    ORDER BY defrag_mapping\n",
    "    \"\"\"),\n",
    "  \"defrag_piece_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6271225b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T15:02:12.131938Z",
     "iopub.status.busy": "2024-10-14T15:02:12.130746Z",
     "iopub.status.idle": "2024-10-14T15:03:03.033887Z",
     "shell.execute_reply": "2024-10-14T15:03:03.032673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:96</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(17);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 48\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:96</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(18);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 48\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:96</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(21);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 26\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:92</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(22);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 1\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mupdated_piece_id_mappings\u001b[39m: \u001b[32mDataFrame\u001b[39m = [orig_piece_id: bigint, defrag_piece_id: bigint]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val updated_piece_id_mappings = materialise_a3s(\"piece_id_mappings\", spark.sql(\"\"\"\n",
    "SELECT orig_piece_id, defrag_piece_id FROM piece_id_mappings_tmp\n",
    "INNER JOIN defrag_id_mapping USING(defrag_mapping)\n",
    "\"\"\"))\n",
    "// delete the temporary mapping dataframes\n",
    "delete_s3(\"piece_id_mappings_tmp\")\n",
    "delete_s3(\"defrag_id_mapping\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala_2.12"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
