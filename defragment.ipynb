{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33652b14-0a71-4a6d-b2a2-613c5c0ee620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling /home/jovyan/work/etl_textreuse/spark_functionality.scCompiling /home/jovyan/work/etl_textreuse/spark_functionality.sc #2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: No SLF4J providers were found.\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SparkSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"http://spark-notebook:4040\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$exec.$                  \n",
       "\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $exec.spark_functionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c4963b-6c06-41e7-b637-2ad286a4059f",
   "metadata": {},
   "source": [
    "# 1. create piecewise reuses\n",
    "\n",
    "Create version of the reuse data where there is a pieces table recording each piece in a reuse in each text, linked by a textreuses table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6aac42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var comm = Jupyter.notebook.kernel.comm_manager.new_comm('cancel-stage-6dfd5d82-74da-4650-a7f7-c8a209d01690', {});\n",
       "\n",
       "function cancelStage(stageId) {\n",
       "  console.log('Cancelling stage ' + stageId);\n",
       "  comm.send({ 'stageId': stageId });\n",
       "}\n",
       "</script>\n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:116</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(0);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 1\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtextreuses1\u001b[39m: \u001b[32mDataFrame\u001b[39m = [textreuse_id: bigint, trs1_id: bigint ... 7 more fields]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val textreuses1 = get_a3s(\"textreuses\")\n",
    "// uncomment the below to test with a small sample\n",
    "// val rdd = sc.parallelize(textreuses1.take(1000))\n",
    "// val rddDf = spark.createDataFrame(rdd,schema=textreuses1.schema)\n",
    "// val textreuses = materialise_local(\"textreuses\",df=rddDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85cfec99-f6a8-4810-a2aa-88c139cb6159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 1\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val pieces = materialise_row_numbers(\n",
    "    \"orig_pieces\", \n",
    "    spark.sql(\"\"\"\n",
    "    SELECT * FROM (\n",
    "    SELECT  \n",
    "        trs1_id AS trs_id,\n",
    "        trs1_start AS trs_start,\n",
    "        trs1_end AS trs_end \n",
    "    FROM textreuses\n",
    "    UNION\n",
    "    SELECT\n",
    "        trs2_id AS trs_id,\n",
    "        trs2_start AS trs_start,\n",
    "        trs2_end AS trs_end \n",
    "    FROM textreuses\n",
    "    )\n",
    "    ORDER BY trs_id,trs_start,trs_end\n",
    "    \"\"\"),\n",
    "    \"piece_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "200bc9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:116</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(24);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 1\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36morig_textreuses\u001b[39m: \u001b[32mDataFrame\u001b[39m = [textreuse_id: bigint, piece1_id: bigint ... 3 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val orig_textreuses = materialise_a3s_if_not_exists(\n",
    "    \"orig_textreuses\",\n",
    "    spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        t.textreuse_id, \n",
    "        op1.piece_id AS piece1_id, \n",
    "        op2.piece_id AS piece2_id,\n",
    "        t.align_length,\n",
    "        t.positives_percent \n",
    "    FROM textreuses t\n",
    "    LEFT JOIN orig_pieces op1 ON t.trs1_id = op1.trs_id AND t.trs1_start=op1.trs_start AND t.trs1_end=op1.trs_end\n",
    "    LEFT JOIN orig_pieces op2 ON t.trs2_id = op2.trs_id AND t.trs2_start=op2.trs_start AND t.trs2_end=op2.trs_end\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2734c922-0268-468f-bfb9-d8dd5cccd72a",
   "metadata": {},
   "source": [
    "# 2. Defragment overlapping pieces to one id\n",
    "\n",
    "Create an initial defragmentation of the piece_ids by mapping all pieces that overlap sufficiently in a given text document to one id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f65a2c-344e-41d2-82eb-463b7ad36ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types.{StructType, StructField, IntegerType, ArrayType}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.catalyst.encoders.RowEncoder\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36minput_type\u001b[39m: \u001b[32mStructType\u001b[39m = \u001b[33mStructType\u001b[39m(\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"trs_start\"\u001b[39m, IntegerType, \u001b[32mtrue\u001b[39m, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"trs_end\"\u001b[39m, IntegerType, \u001b[32mtrue\u001b[39m, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"piece_id\"\u001b[39m, IntegerType, \u001b[32mtrue\u001b[39m, {})\n",
       ")\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable.ArrayBuffer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Aggregator\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mobject\u001b[39m \u001b[36mGetPieceIdMapping\u001b[39m\n",
       "\u001b[36mres10_7\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mUserDefinedFunction\u001b[39m = \u001b[33mUserDefinedAggregator\u001b[39m(\n",
       "  ammonite.$sess.cmd10$Helper$GetPieceIdMapping$@52d964a3,\n",
       "  \u001b[33mExpressionEncoder\u001b[39m(\n",
       "    \u001b[33mIf\u001b[39m(\n",
       "      \u001b[33mIsNull\u001b[39m(\n",
       "        \u001b[33mBoundReference\u001b[39m(\u001b[32m0\u001b[39m, \u001b[33mObjectType\u001b[39m(interface org.apache.spark.sql.Row), \u001b[32mtrue\u001b[39m)\n",
       "      ),\n",
       "      \u001b[33mLiteral\u001b[39m(\n",
       "        \u001b[32mnull\u001b[39m,\n",
       "        \u001b[33mStructType\u001b[39m(\n",
       "          \u001b[33mStructField\u001b[39m(\u001b[32m\"trs_start\"\u001b[39m, IntegerType, \u001b[32mtrue\u001b[39m, {}),\n",
       "          \u001b[33mStructField\u001b[39m(\u001b[32m\"trs_end\"\u001b[39m, IntegerType, \u001b[32mtrue\u001b[39m, {}),\n",
       "          \u001b[33mStructField\u001b[39m(\u001b[32m\"piece_id\"\u001b[39m, IntegerType, \u001b[32mtrue\u001b[39m, {})\n",
       "        )\n",
       "      ),\n",
       "      \u001b[33mCreateNamedStruct\u001b[39m(\n",
       "        \u001b[33mArraySeq\u001b[39m(\n",
       "          \u001b[33mLiteral\u001b[39m(trs_start, StringType),\n",
       "          \u001b[33mIf\u001b[39m(\n",
       "            \u001b[33mInvoke\u001b[39m(\n",
       "              \u001b[33mBoundReference\u001b[39m(\n",
       "                \u001b[32m0\u001b[39m,\n",
       "                \u001b[33mObjectType\u001b[39m(interface org.apache.spark.sql.Row),\n",
       "                \u001b[32mtrue\u001b[39m\n",
       "              ),\n",
       "              \u001b[32m\"isNullAt\"\u001b[39m,\n",
       "              BooleanType,\n",
       "              \u001b[33mList\u001b[39m(\u001b[33mLiteral\u001b[39m(\u001b[32m0\u001b[39m, IntegerType)),\n",
       "              \u001b[33mList\u001b[39m(),\n",
       "              \u001b[32mtrue\u001b[39m,\n",
       "              \u001b[32mtrue\u001b[39m,\n",
       "              \u001b[32mtrue\u001b[39m\n",
       "            ),\n",
       "            \u001b[33mLiteral\u001b[39m(\u001b[32mnull\u001b[39m, IntegerType),\n",
       "            \u001b[33mValidateExternalType\u001b[39m(\n",
       "              \u001b[33mGetExternalRowField\u001b[39m(\n",
       "                \u001b[33mBoundReference\u001b[39m(\n",
       "                  \u001b[32m0\u001b[39m,\n",
       "                  \u001b[33mObjectType\u001b[39m(interface org.apache.spark.sql.Row),\n",
       "..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, ArrayType}\n",
    "import org.apache.spark.sql.catalyst.encoders.RowEncoder\n",
    "\n",
    "val input_type = StructType(Seq(\n",
    "    StructField(\"trs_start\",IntegerType),\n",
    "    StructField(\"trs_end\",IntegerType),\n",
    "    StructField(\"piece_id\",IntegerType)\n",
    "))\n",
    "\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "import org.apache.spark.sql.expressions.Aggregator\n",
    "\n",
    "object GetPieceIdMapping extends Aggregator[Row, ArrayBuffer[(Int,Int,Int)], Int] {\n",
    "  import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n",
    "\n",
    "  // A zero value for this aggregation. Should satisfy the property that any b + zero = b\n",
    "  def zero: ArrayBuffer[(Int,Int,Int)] = ArrayBuffer()\n",
    "  // Combine two values to produce a new value. For performance, the function may modify `buffer`\n",
    "  // and return it instead of constructing a new object\n",
    "  def reduce(to_check: ArrayBuffer[(Int,Int,Int)], row: Row): ArrayBuffer[(Int,Int,Int)] = {\n",
    "      val t_start = row.getInt(0)\n",
    "      // check existing buffer for the last piece that is 180 characters \n",
    "      // before the current start offset\n",
    "      val idx = to_check.indexWhere(_._1 >= t_start - 180)\n",
    "      // if 0 then clear the buffer\n",
    "      // otherwise remove unsuitable pieces\n",
    "      if (idx < 0) to_check.clear() else to_check.remove(0, idx)\n",
    "      // add the current piece to the end of buffer\n",
    "      to_check += ((t_start,row.getInt(1),row.getInt(2)))\n",
    "      to_check\n",
    "  }\n",
    "  // Merge two intermediate values\n",
    "  def merge(b1: ArrayBuffer[(Int,Int,Int)], b2: ArrayBuffer[(Int,Int,Int)]): ArrayBuffer[(Int,Int,Int)] = {\n",
    "//      b1 ++= b2 & sort\n",
    "      throw new UnsupportedOperationException()\n",
    "  }\n",
    "  // Transform the output of the reduction\n",
    "  def finish(to_check: ArrayBuffer[(Int,Int,Int)]): Int = {\n",
    "      val (t_start, t_end, piece_id) = to_check.last\n",
    "      to_check.find(r => {\n",
    "          val limit = math.min(\n",
    "              math.max(\n",
    "                  math.min(t_end - t_start, r._2 - r._1)\n",
    "                  /4, 10),\n",
    "              180)\n",
    "          math.abs(r._1 - t_start) <= limit && math.abs(r._2 - t_end) <= limit\n",
    "      }).get._3 // get the id of the first piece that is valid\n",
    "  }\n",
    "  // Specifies the Encoder for the intermediate value type\n",
    "  def bufferEncoder: Encoder[ArrayBuffer[(Int,Int,Int)]] = ExpressionEncoder()\n",
    "  // Specifies the Encoder for the final output value type\n",
    "  def outputEncoder: Encoder[Int] = Encoders.scalaInt\n",
    "}\n",
    "\n",
    "// Register the function to access it\n",
    "spark.udf.register(\"get_piece_id_mapping\", functions.udaf(GetPieceIdMapping,RowEncoder(input_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f41c5e25-f3d4-4063-ac4a-d7bb359a8a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:116</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(25);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 1\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mpiece_id_mappings\u001b[39m: \u001b[32mDataFrame\u001b[39m = [orig_piece_id: bigint, defrag_mapping: int]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val piece_id_mappings = materialise_a3s_if_not_exists(\n",
    "    \"piece_id_mappings_tmp\", \n",
    "    spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        piece_id AS orig_piece_id,\n",
    "        get_piece_id_mapping(trs_start,trs_end,piece_id) \n",
    "            OVER (PARTITION BY trs_id ORDER BY trs_start, piece_id) \n",
    "            AS defrag_mapping\n",
    "    FROM orig_pieces\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d5665",
   "metadata": {},
   "source": [
    "We convert the mapping ids into monotonically increasing ids for new defragmented pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03987e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">rdd at spark_functionality.sc:158</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(26);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 25\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 34\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 34\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 33\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 34\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:116</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(37);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 1\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "materialise_row_numbers(\n",
    "  \"defrag_id_mapping\",\n",
    "  spark.sql(\"\"\"\n",
    "    SELECT DISTINCT defrag_mapping\n",
    "    FROM piece_id_mappings_tmp\n",
    "    ORDER BY defrag_mapping\n",
    "    \"\"\"),\n",
    "  \"defrag_piece_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af01d34",
   "metadata": {},
   "source": [
    "Add the piece id mapping back to piece_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01483caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:120</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(38);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 34\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:120</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(39);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 34\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:120</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(42);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 200\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:116</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(43);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 1\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mupdated_piece_id_mappings\u001b[39m: \u001b[32mDataFrame\u001b[39m = [orig_piece_id: bigint, defrag_piece_id: bigint]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val updated_piece_id_mappings = materialise_a3s(\"piece_id_mappings\", spark.sql(\"\"\"\n",
    "SELECT orig_piece_id, defrag_piece_id FROM piece_id_mappings_tmp\n",
    "INNER JOIN defrag_id_mapping USING(defrag_mapping)\n",
    "\"\"\"))\n",
    "// delete the temporary mapping dataframes\n",
    "delete_s3(\"piece_id_mappings_tmp\")\n",
    "delete_s3(\"defrag_id_mapping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ffae23-ab7f-44bb-81e7-502d50fd946c",
   "metadata": {},
   "source": [
    "## 3. Gather defragmented pieces and resulting edges\n",
    "\n",
    "First gather the defragmented edges and their offset boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b471b678-9260-4e38-999f-6beecd8a5ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 34\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:120</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(45);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 43\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:120</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(48);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 200\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:120</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(52);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 200\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:116</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(53);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 1\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdefrag_pieces\u001b[39m: \u001b[32mDataFrame\u001b[39m = [piece_id: bigint, trs_id: bigint ... 2 more fields]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val defrag_pieces = materialise_a3s(\"defrag_pieces\", spark.sql(\"\"\"\n",
    "SELECT defrag_piece_id AS piece_id, trs_id, MIN(trs_start) AS trs_start, MAX(trs_end) AS trs_end\n",
    "FROM piece_id_mappings\n",
    "INNER JOIN orig_pieces ON piece_id = orig_piece_id\n",
    "GROUP BY defrag_piece_id, trs_id\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd5724",
   "metadata": {},
   "source": [
    "Map the reuses from the original pieces to the defragmeneted pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86d36669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">rdd at spark_functionality.sc:158</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(54);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 100\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">rdd at spark_functionality.sc:158</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(55);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 34\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">rdd at spark_functionality.sc:158</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(58);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 200\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 200\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">rdd at spark_functionality.sc:158</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(67);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 200\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">rdd at spark_functionality.sc:158</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(72);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 200\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 199\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left; word-wrap: normal; white-space: nowrap; text-align: center\">parquet at spark_functionality.sc:120</span>\n",
       "  <span style=\"float: right; word-wrap: normal; white-space: nowrap; text-align: center\"><a href=\"#\" onclick=\"cancelStage(84);\">(kill)</a></span>\n",
       "</div>\n",
       "<br>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 200\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 1\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "materialise_row_numbers(\n",
    "    \"defrag_textreuses\",\n",
    "    spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        pm1.defrag_piece_id AS piece1_id, \n",
    "        pm2.defrag_piece_id AS piece2_id,\n",
    "        COUNT(*) AS num_orig_links\n",
    "    FROM orig_textreuses tr\n",
    "    LEFT JOIN piece_id_mappings pm1 ON (tr.piece1_id=pm1.orig_piece_id)\n",
    "    LEFT JOIN piece_id_mappings pm2 ON (tr.piece2_id=pm2.orig_piece_id)\n",
    "    GROUP BY pm1.defrag_piece_id,pm2.defrag_piece_id\n",
    "    ORDER BY piece1_id,piece2_id\n",
    "    \"\"\"),\n",
    "    \"textreuse_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45b0673-d6fa-4596-879f-27c7e1bad1fb",
   "metadata": {},
   "source": [
    "# 4. Create adjacency list for clustering\n",
    "\n",
    "Create a parquet file containing the defragmented textreuse network in the the form of an adjacency list. Also ensure that all nodes (i.e., defragmented pieces) are 0-indexed. Therefore, each array index contains the indices of other nodes it links to. Also coalese into a single partition for the clustering code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fad3f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 1\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar bg-success\" role=\"progressbar\" style=\"width: 0%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    0 / 82\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val defrag_textreuses = get_a3s(\"defrag_textreuses\")\n",
    "\n",
    "materialise_a3s(\n",
    "    \"defrag_graph_adj_list\",\n",
    "    spark.sql(\"\"\"\n",
    "    WITH undirected_edges AS (\n",
    "      SELECT piece1_id-1 as piece1_id, piece2_id-1 as piece2_id FROM defrag_textreuses\n",
    "      UNION ALL\n",
    "      SELECT piece2_id-1 AS piece1_id, piece1_id-1 AS piece2_id FROM defrag_textreuses\n",
    "    )\n",
    "    SELECT /*+ REPARTITION(1)*/ collect_list(piece2_id) AS edges\n",
    "    FROM undirected_edges\n",
    "    GROUP BY piece1_id\n",
    "    ORDER BY piece1_id\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b608fd54-6485-4ce7-b1f7-6c136d131855",
   "metadata": {},
   "source": [
    "# 5. clustering \n",
    "\n",
    "Done separately with the Go versionn of the Chinese Whispers algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e0944",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala_2.12"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
